{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../chunk_caption_component/')\n",
    "sys.path.append('../enhanced_doc_analyzer_component/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# Example of registering the component in a workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.ai.ml import load_component, load_environment\n",
    "from azure.ai.ml import dsl, Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.entities._job.pipeline._io import PipelineInput\n",
    "from typing import Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "ml_registry = MLClient(credential=DefaultAzureCredential(), registry_name=\"azureml\")\n",
    "\n",
    "# Reads input folder of files containing chunks and their metadata as batches, in parallel, and generates embeddings for each chunk. Output format is produced and loaded by `azureml.rag.embeddings.EmbeddingContainer`.\n",
    "generate_embeddings_component = ml_registry.components.get(\n",
    "    \"llm_rag_generate_embeddings\", label=\"latest\"\n",
    ")\n",
    "# Reads an input folder produced by `azureml.rag.embeddings.EmbeddingsContainer.save()` and pushes all documents (chunk, metadata, embedding_vector) into an Azure Cognitive Search index. Writes an MLIndex yaml detailing the index and embeddings model information.\n",
    "update_acs_index_component = ml_registry.components.get(\n",
    "    \"llm_rag_update_acs_index\", label=\"latest\"\n",
    ")\n",
    "# Takes a uri to a storage location where an MLIndex yaml is stored and registers it as an MLIndex Data asset in the AzureML Workspace.\n",
    "register_mlindex_component = ml_registry.components.get(\n",
    "    \"llm_rag_register_mlindex_asset\", label=\"latest\"\n",
    ")\n",
    "\n",
    "# Load components and environment\n",
    "analyzer_component = load_component(source=\"./enhanced_doc_analyzer_component/doc_analyzer_component.yaml\")\n",
    "chunk_caption_index = load_component(source=\"./chuck_caption_component/chuck_caption_component.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.rag.utils.deployment import infer_deployment\n",
    "from azureml.rag.utils.connections import get_connection_by_id_v2\n",
    "\n",
    "aoai_connection_name = \"open_ai_connection\"\n",
    "acs_connection_name = \"acs-connection\"\n",
    "data_set_name = \"papers\"\n",
    "asset_name = \"aoai_acs_mlindex\"\n",
    "doc_intelligence_connection_name = \"doc-intelligence-connection\"\n",
    "vision_deploy_name = \"gpt-4\"\n",
    "aoai_embedding_model_name = \"text-embedding-3-large\"\n",
    "\n",
    "acs_config = {\n",
    "    \"index_name\": \"qknows-embedding\",\n",
    "}\n",
    "\n",
    "experiment_name = \"sample-acs-embedding\"\n",
    "\n",
    "aoai_connection_id = ml_client.connections.get(aoai_connection_name).id\n",
    "aoai_connection = get_connection_by_id_v2(aoai_connection_id)\n",
    "\n",
    "\n",
    "\n",
    "embeddings_model_uri = f\"azure_open_ai://deployment/{aoai_embedding_model_name}/model/{aoai_embedding_model_name}\"\n",
    "# embeddings_model = \"hugging_face://model/sentence-transformers/all-mpnet-base-v2\"\n",
    "embeddings_model = embeddings_model_uri\n",
    "\n",
    "\n",
    "doc_intelligence_connection = ml_client.connections.get(doc_intelligence_connection_name)\n",
    "acs_connection = ml_client.connections.get(acs_connection_name)\n",
    "\n",
    "# Get the data asset with version\n",
    "raw_papers = ml_client.data.get(data_set_name, version=\"1\")\n",
    "# Create Input object for the data\n",
    "pdf_input = Input(type=AssetTypes.URI_FOLDER, path=raw_papers.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optional_pipeline_input_provided(input: Optional[PipelineInput]):\n",
    "    \"\"\"Checks if optional pipeline inputs are provided.\"\"\"\n",
    "    return input is not None and input._data is not None\n",
    "\n",
    "def use_automatic_compute(component, instance_count=1, instance_type=\"Standard_E8s_v3\"):\n",
    "    \"\"\"Configure input `component` to use automatic compute with `instance_count` and `instance_type`.\n",
    "\n",
    "    This avoids the need to provision a compute cluster to run the component.\n",
    "    \"\"\"\n",
    "    component.set_resources(\n",
    "        instance_count=instance_count,\n",
    "        instance_type=instance_type,\n",
    "        properties={\"compute_specification\": {\"automatic\": True}},\n",
    "    )\n",
    "    return component\n",
    "\n",
    "@dsl.pipeline(\n",
    "    description=\"Combined document analysis and azure AI search indexing pipeline\",\n",
    "    default_compute=\"cpu-cluster-low\",\n",
    ")\n",
    "def document_processing_pipeline(\n",
    "    # Document Analyzer inputs\n",
    "    \n",
    "    pdf_folder,\n",
    "    asset_name: str,\n",
    "    doc_intel_connection_id: str,\n",
    "    acs_config: str,\n",
    "    acs_connection_id: str,\n",
    "    confidence_threshold: float = 0.5,\n",
    "    min_length: int = 10,\n",
    "    overlap_threshold: float = 0.5,\n",
    "    ignore_roles: str = \"pageFooter,footnote,pageHeader\",\n",
    "    vision_deployment_name: str = \"gpt-4\",\n",
    "    embeddings_model: str = \"hugging_face://model/sentence-transformers/all-mpnet-base-v2\",\n",
    "    embeddings_container=None,\n",
    "    aoai_connection_id: str = None,\n",
    "    # Compute settings\n",
    "    analyzer_compute: str = \"gpu-cluster-a100\",\n",
    "    indexer_compute: str = \"cpu-cluster-low\"\n",
    "\n",
    "):\n",
    "    # Document Analyzer step\n",
    "    analysis_job = analyzer_component(\n",
    "        input_folder=pdf_folder,\n",
    "        doc_intel_connection_id=doc_intel_connection_id,\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        min_length=min_length,\n",
    "        overlap_threshold=overlap_threshold,\n",
    "        ignore_roles=ignore_roles\n",
    "    )\n",
    "    analysis_job.compute = analyzer_compute\n",
    "\n",
    "    # Chunk Caption Index step\n",
    "    # Using the output from document analyzer as input\n",
    "    chunk_caption_job = chunk_caption_index(\n",
    "        input_folder=analysis_job.outputs.output_dir,\n",
    "        azure_openai_connection_id=aoai_connection_id,\n",
    "        vision_deployment_name=vision_deployment_name,\n",
    "    )\n",
    "    chunk_caption_job.compute = indexer_compute\n",
    "\n",
    "    generate_embeddings = generate_embeddings_component(\n",
    "        chunks_source=chunk_caption_job.outputs.output_folder,\n",
    "        embeddings_container=embeddings_container,\n",
    "        embeddings_model=embeddings_model,\n",
    "    )\n",
    "    # use_automatic_compute(generate_embeddings)\n",
    "    generate_embeddings.compute = indexer_compute\n",
    "    if optional_pipeline_input_provided(aoai_connection_id):\n",
    "        generate_embeddings.environment_variables[\n",
    "            \"AZUREML_WORKSPACE_CONNECTION_ID_AOAI\"\n",
    "        ] = aoai_connection_id\n",
    "    if optional_pipeline_input_provided(embeddings_container):\n",
    "        # If provided, `embeddings_container` is expected to be a URI to folder, the folder can be empty.\n",
    "        # Each sub-folder is generated by a `create_embeddings_component` run and can be reused for subsequent embeddings runs.\n",
    "        generate_embeddings.outputs.embeddings = Output(\n",
    "            type=\"uri_folder\", path=f\"{embeddings_container.path}/{{name}}\"\n",
    "        )\n",
    "\n",
    "    # `update_acs_index` takes the Embedded data produced by `generate_embeddings` and pushes it into an Azure Cognitive Search index.\n",
    "    update_acs_index = update_acs_index_component(\n",
    "        embeddings=generate_embeddings.outputs.embeddings, acs_config=acs_config\n",
    "    )\n",
    "    # use_automatic_compute(update_acs_index)\n",
    "    update_acs_index.compute = indexer_compute\n",
    "    if optional_pipeline_input_provided(acs_connection_id):\n",
    "        update_acs_index.environment_variables[\n",
    "            \"AZUREML_WORKSPACE_CONNECTION_ID_ACS\"\n",
    "        ] = acs_connection_id\n",
    "\n",
    "    register_mlindex = register_mlindex_component(\n",
    "        storage_uri=update_acs_index.outputs.index, asset_name=asset_name\n",
    "    )\n",
    "    # use_automatic_compute(register_mlindex)\n",
    "    register_mlindex.compute = indexer_compute\n",
    "    return {\n",
    "        \"mlindex_asset_uri\": update_acs_index.outputs.index,\n",
    "        \"mlindex_asset_id\": register_mlindex.outputs.asset_id,\n",
    "        \"analyzer_output\": analysis_job.outputs.output_dir,\n",
    "        \"final_output\": chunk_caption_job.outputs.output_folder\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = document_processing_pipeline(\n",
    "    # Document Analyzer params\n",
    "    pdf_folder=pdf_input,\n",
    "    asset_name=asset_name,\n",
    "    doc_intel_connection_id=doc_intelligence_connection.id,\n",
    "    acs_config=json.dumps(acs_config),\n",
    "    acs_connection_id=acs_connection.id,\n",
    "    confidence_threshold=0.3,\n",
    "    min_length=15,\n",
    "    overlap_threshold=0.7,\n",
    "    ignore_roles=\"pageFooter,footnote,pageHeader\",\n",
    "    \n",
    "    # Chunk Caption Index params\n",
    "    aoai_connection_id=aoai_connection_id,\n",
    "    vision_deployment_name=vision_deploy_name,\n",
    "    embeddings_model=embeddings_model,\n",
    "    embeddings_container=None,\n",
    "    \n",
    "    # Compute settings\n",
    "    analyzer_compute=\"gpu-cluster-a100\",\n",
    "    indexer_compute=\"cpu-cluster-low\"\n",
    ")\n",
    "\n",
    "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
    "pipeline.properties[\"azureml.mlIndexAssetName\"] = asset_name\n",
    "pipeline.properties[\"azureml.mlIndexAssetKind\"] = \"acs\"\n",
    "pipeline.properties[\"azureml.mlIndexAssetSource\"] = \"raw_papers\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Submit the pipeline\n",
    "run = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"document-processin-aml-components-pipeline\",\n",
    "    tags={\"type\": \"document-processing\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlException",
     "evalue": "\n\u001b[37m\n\u001b[30m\n1) Resource was not found.\n\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Asset aoai_acs_mlindex does not exist in workspace mlw-acadocser-dev-04.\u001b[39m\n\nResolutions: \n1) Double-check that the resource has been specified correctly and that you have access to it.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:775\u001b[0m, in \u001b[0;36m_get_latest_version_from_container\u001b[0;34m(asset_name, container_operation, resource_group_name, workspace_name, registry_name, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    767\u001b[0m     container \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    768\u001b[0m         container_operation\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    769\u001b[0m             name\u001b[38;5;241m=\u001b[39masset_name,\n\u001b[1;32m    770\u001b[0m             resource_group_name\u001b[38;5;241m=\u001b[39mresource_group_name,\n\u001b[1;32m    771\u001b[0m             registry_name\u001b[38;5;241m=\u001b[39mregistry_name,\n\u001b[1;32m    772\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    773\u001b[0m         )\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m registry_name\n\u001b[0;32m--> 775\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcontainer_operation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresource_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m            \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m     )\n\u001b[1;32m    782\u001b[0m     version \u001b[38;5;241m=\u001b[39m container\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mlatest_version\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/tracing/decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_restclient/v2023_04_01_preview/operations/_data_containers_operations.py:430\u001b[0m, in \u001b[0;36mDataContainersOperations.get\u001b[0;34m(self, resource_group_name, workspace_name, name, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m--> 430\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/exceptions.py:161\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: (UserError) aoai_acs_mlindex container was not found.\nCode: UserError\nMessage: aoai_acs_mlindex container was not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_data_operations.py:265\u001b[0m, in \u001b[0;36mDataOperations.get\u001b[0;34m(self, name, version, label)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resolve_label_to_asset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:1022\u001b[0m, in \u001b[0;36m_resolve_label_to_asset\u001b[0;34m(assetOperations, name, label)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1017\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(name, label, scope),\n\u001b[1;32m   1018\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[name]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[label]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[scope]\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1019\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mASSET,\n\u001b[1;32m   1020\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mRESOURCE_NOT_FOUND,\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[0;32m-> 1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_data_operations.py:675\u001b[0m, in \u001b[0;36mDataOperations._get_latest_version\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the latest version of the asset with the given name. Latest is defined as the most recently created,\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m not the most recently updated.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03m:rtype: Data\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m latest_version \u001b[38;5;241m=\u001b[39m \u001b[43m_get_latest_version_from_container\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_container_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_group_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registry_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(name, version\u001b[38;5;241m=\u001b[39mlatest_version)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_utils/_asset_utils.py:795\u001b[0m, in \u001b[0;36m_get_latest_version_from_container\u001b[0;34m(asset_name, container_operation, resource_group_name, workspace_name, registry_name, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     no_personal_data_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsset \u001b[39m\u001b[38;5;132;01m{asset_name}\u001b[39;00m\u001b[38;5;124m does not exist in registry \u001b[39m\u001b[38;5;132;01m{registry_name}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m registry_name\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsset \u001b[39m\u001b[38;5;132;01m{asset_name}\u001b[39;00m\u001b[38;5;124m does not exist in workspace \u001b[39m\u001b[38;5;132;01m{workspace_name}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m     )\n\u001b[0;32m--> 795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationException(\n\u001b[1;32m    796\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m    797\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mno_personal_data_message,\n\u001b[1;32m    798\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mASSET,\n\u001b[1;32m    799\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    800\u001b[0m         error_type\u001b[38;5;241m=\u001b[39mValidationErrorType\u001b[38;5;241m.\u001b[39mRESOURCE_NOT_FOUND,\n\u001b[1;32m    801\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m version\n",
      "\u001b[0;31mValidationException\u001b[0m: Asset aoai_acs_mlindex does not exist in workspace mlw-acadocser-dev-04.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLIndex\n\u001b[1;32m      5\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow many steps are in metalloporphyrins synthesis?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m faias_retriever \u001b[38;5;241m=\u001b[39m MLIndex(\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m )\u001b[38;5;241m.\u001b[39mas_langchain_retriever()\n\u001b[1;32m     10\u001b[0m retriever\u001b[38;5;241m.\u001b[39mget_relevant_documents(question)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:289\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mspan():\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    287\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    288\u001b[0m         ):\n\u001b[0;32m--> 289\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/operations/_data_operations.py:279\u001b[0m, in \u001b[0;36mDataOperations.get\u001b[0;34m(self, name, version, label)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Data\u001b[38;5;241m.\u001b[39m_from_rest_object(data_version_resource)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationException, SchemaValidationError) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mlog_and_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/ml/_exception_helper.py:337\u001b[0m, in \u001b[0;36mlog_and_raise_error\u001b[0;34m(error, debug, yaml_operation)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MlException(message\u001b[38;5;241m=\u001b[39mformatted_error, no_personal_data_message\u001b[38;5;241m=\u001b[39mformatted_error)\n",
      "\u001b[0;31mMlException\u001b[0m: \n\u001b[37m\n\u001b[30m\n1) Resource was not found.\n\u001b[39m\u001b[39m\n\nDetails: \n\n\u001b[31m(x) Asset aoai_acs_mlindex does not exist in workspace mlw-acadocser-dev-04.\u001b[39m\n\nResolutions: \n1) Double-check that the resource has been specified correctly and that you have access to it.\nIf using the CLI, you can also check the full log in debug mode for more details by adding --debug to the end of your command\n\nAdditional Resources: The easiest way to author a yaml specification file is using IntelliSense and auto-completion Azure ML VS code extension provides: \u001b[36mhttps://code.visualstudio.com/docs/datascience/azure-machine-learning.\u001b[39m To set up VS Code, visit \u001b[36mhttps://docs.microsoft.com/azure/machine-learning/how-to-setup-vs-code\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "from azureml.rag.mlindex import MLIndex\n",
    "\n",
    "\n",
    "\n",
    "question = \"how many steps are in metalloporphyrins synthesis?\"\n",
    "\n",
    "faias_retriever = MLIndex(\n",
    "    ml_client.data.get(asset_name, label=\"latest\")\n",
    ").as_langchain_retriever()\n",
    "retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.rag.utils.connections import get_connection_by_id_v2\n",
    "\n",
    "aoai_connection_id = ml_client.connections.get(\"aoai-sweden-505\").id\n",
    "aoai_connection = get_connection_by_id_v2(aoai_connection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/nougat/lib/python3.9/site-packages/azureml/rag/models.py:276: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  llm = AzureChatOpenAI(\n",
      "/tmp/ipykernel_213310/3078494376.py:22: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa.run(question)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know the answer to how many steps are in metalloporph\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from azureml.rag.models import init_llm, parse_model_uri\n",
    "\n",
    "model_config = parse_model_uri(\n",
    "    \"azure_open_ai://deployment/gpt-35-turbo/model/gpt-35-turbo\"\n",
    ")\n",
    "model_config[\"azure_endpoint\"] = aoai_connection.target\n",
    "model_config[\"api_key\"] = aoai_connection.api_key\n",
    "model_config[\"temperature\"] = 0.3\n",
    "model_config[\"max_retries\"] = 3\n",
    "model_config[\"deployment\"] = \"gpt-4v\"\n",
    "model_config[\"model\"] = \"gpt-4\"\n",
    "\n",
    "llm=init_llm(model_config)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "qa.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriever, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source_doc_id': 'Eur J Org Chem - 2020 - Breugst - ‐Hole Interactions in Catalysis.pdf', 'chunk_hash': '3116fd17b82e85c53f20791851eea6d233b0edc9d0935a70b463e76335f81c51', 'mtime': None, 'page_number': 15, 'stats': {'tiktokens': 9, 'chars': 22, 'lines': 1}, 'source': {'filename': 'Eur J Org Chem - 2020 - Breugst - ‐Hole Interactions in Catalysis.pdf', 'url': '', 'mtime': None, 'role': nan, 'image_path': nan, 'confidence': nan, 'source': 'azure_document_intelligence', 'bounding_box': '(4.20, 7.24, 5.24, 7.36)', 'page': 15, 'id': '24fdc787-653a-4770-959f-f13ff2a62693'}}, page_content='Received: May 13, 2020'),\n",
       " Document(metadata={'source_doc_id': 'ChemBioChem - 2020 - Valverde - Molecular Recognition in C‐Type Lectins  The Cases of DC‐SIGN  Langerin  MGL  and L‐Sectin.pdf', 'chunk_hash': 'ef66b46c575b5eaadb34e2e9285b1a1e5a5e2ef20559dcad04b62ecb35b997e7', 'mtime': None, 'page_number': 25, 'stats': {'tiktokens': 62, 'chars': 124, 'lines': 1}, 'source': {'filename': 'ChemBioChem - 2020 - Valverde - Molecular Recognition in C‐Type Lectins  The Cases of DC‐SIGN  Langerin  MGL  and L‐Sectin.pdf', 'url': '', 'mtime': None, 'role': nan, 'image_path': nan, 'confidence': nan, 'source': 'azure_document_intelligence', 'bounding_box': '(4.22, 7.86, 7.61, 8.10)', 'page': 25, 'id': 'f5b63d55-2a7c-4f71-a97d-4879be79c6a7'}}, page_content='[183] H. Feinberg, T. J. Rowntree, S. L. Tan, K. Drickamer, W. I. Weis, M. E. Taylor, J. Biol. Chem. 2013, 288, 36762-36771.'),\n",
       " Document(metadata={'source_doc_id': '1-s2.0-S0927796X2030053X-am.pdf', 'chunk_hash': '3ed08b53b72471017a123dea7fd48639660dc726f693bb24b7ef341364da1b45', 'mtime': None, 'page_number': 28, 'stats': {'tiktokens': 74, 'chars': 200, 'lines': 1}, 'source': {'filename': '1-s2.0-S0927796X2030053X-am.pdf', 'url': '', 'mtime': None, 'role': nan, 'image_path': nan, 'confidence': nan, 'source': 'azure_document_intelligence', 'bounding_box': '(0.89, 4.99, 7.37, 5.26)', 'page': 28, 'id': '85054442-d9ff-4ea4-b03a-4884424bd2d2'}}, page_content='[172] M. M. Noack, K. G. Yager, M. Fukuto, G. S. Doerk, R. Li, J. A. Sethian, A kriging-based approach to autonomous experimentation with applications to x-ray scattering, Sci. Rep. 9 (1) (2019) 1-19.'),\n",
       " Document(metadata={'source_doc_id': '2412.20995v1.pdf', 'chunk_hash': '46491784326478e7a78b8370713be65ebb05ea853276b6f79b2fa006930b0b0d', 'mtime': None, 'page_number': 23, 'stats': {'tiktokens': 17, 'chars': 71, 'lines': 1}, 'source': {'filename': '2412.20995v1.pdf', 'url': '', 'mtime': None, 'role': nan, 'image_path': '2412.20995v1/elements/picture/page_23_Picture_23035456701632.png', 'confidence': 0.3221456110477447, 'source': 'layout_detector', 'bounding_box': '(438.29, 227.81, 601.50, 307.09)', 'page': 23, 'id': '2a473ebc-3ea7-49b9-8165-00c61785d8a9'}}, page_content='The image shows the word \"Reasoning\" in red font on a white background.'),\n",
       " Document(metadata={'source_doc_id': 'ChemBioChem-2020PorphyrinsColorimetricPhotometricBiosensorsModernBioanalyticalSystems.pdf', 'chunk_hash': 'e76b4acff71c007fec800d80d7be09442b0139db06af4b54bc29f602ced0f28b', 'mtime': None, 'page_number': 15, 'stats': {'tiktokens': 35, 'chars': 121, 'lines': 1}, 'source': {'filename': 'ChemBioChem-2020PorphyrinsColorimetricPhotometricBiosensorsModernBioanalyticalSystems.pdf', 'url': '', 'mtime': None, 'role': nan, 'image_path': nan, 'confidence': nan, 'source': 'azure_document_intelligence', 'bounding_box': '(4.21, 1.90, 6.15, 2.27)', 'page': 15, 'id': '47d62392-30f8-4143-86d5-119a9ca67a40'}}, page_content='Manuscript received: February 1, 2020 Revised manuscript received: March 4, 2020 Version of record online: March 30, 2020')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_from_llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_from_llm\n",
    ")\n",
    "\n",
    "qa.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
