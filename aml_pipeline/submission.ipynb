{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../chunk_caption_index_component/')\n",
    "sys.path.append('../enhanced_doc_analyzer_component/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "# Example of registering the component in a workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import dsl, Input\n",
    "from azure.ai.ml import load_component, load_environment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Load components and environment\n",
    "analyzer_component = load_component(source=\"./enhanced_doc_analyzer_component/doc_analyzer_component.yaml\")\n",
    "chunk_caption_index = load_component(source=\"./chunk_caption_index_component/chunk-caption-index-component.yaml\")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    description=\"Combined document analysis and indexing pipeline\",\n",
    "    default_compute=\"gpu-cluster\"\n",
    ")\n",
    "def document_processing_pipeline(\n",
    "    # Document Analyzer inputs\n",
    "    \n",
    "    pdf_folder,\n",
    "    doc_intel_connection_id: str,\n",
    "    azure_openai_connection_id: str,\n",
    "    azure_search_connection_id: str,\n",
    "    confidence_threshold: float = 0.5,\n",
    "    min_length: int = 10,\n",
    "    overlap_threshold: float = 0.5,\n",
    "    ignore_roles: str = \"pageFooter,footnote,pageHeader\",\n",
    "    embd_deployment_name: str = \"text-embedding-ada-002\",\n",
    "    vision_deployment_name: str = \"gpt-4\",\n",
    "    index_name: str = \"myindex\",\n",
    "    # Compute settings\n",
    "    analyzer_compute: str = \"gpu-cluster\",\n",
    "    indexer_compute: str = \"cpu-cluster\"\n",
    "):\n",
    "    # Document Analyzer step\n",
    "    analysis_job = analyzer_component(\n",
    "        input_folder=pdf_folder,\n",
    "        doc_intel_connection_id=doc_intel_connection_id,\n",
    "        confidence_threshold=confidence_threshold,\n",
    "        min_length=min_length,\n",
    "        overlap_threshold=overlap_threshold,\n",
    "        ignore_roles=ignore_roles\n",
    "    )\n",
    "    analysis_job.compute = analyzer_compute\n",
    "\n",
    "    # Chunk Caption Index step\n",
    "    # Using the output from document analyzer as input\n",
    "    chunk_caption_job = chunk_caption_index(\n",
    "        input_folder=analysis_job.outputs.output_dir,\n",
    "        azure_openai_connection_id=azure_openai_connection_id,\n",
    "        azure_search_connection_id=azure_search_connection_id,\n",
    "        embd_deployment_name=embd_deployment_name,\n",
    "        vision_deployment_name=vision_deployment_name,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    chunk_caption_job.compute = indexer_compute\n",
    "\n",
    "    return {\n",
    "        \"analyzer_output\": analysis_job.outputs.output_dir,\n",
    "        \"final_output\": chunk_caption_job.outputs.output_folder\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "def main(ml_client):\n",
    "    # Get connections\n",
    "    doc_intelligence_connection = ml_client.connections.get(\"my-doc-intelligence-connection\")\n",
    "    azure_search_connection = ml_client.connections.get(\"aisearch505\")\n",
    "    azure_openai_connection = ml_client.connections.get(\"aoai-sweden-505\")\n",
    "\n",
    "    # Get the data asset with version\n",
    "    raw_papers = ml_client.data.get(\"raw_papers\", version=\"1\")\n",
    "    # Create Input object for the data\n",
    "    pdf_input = Input(type=AssetTypes.URI_FOLDER, path=raw_papers.path)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = document_processing_pipeline(\n",
    "        # Document Analyzer params\n",
    "        pdf_folder=pdf_input,\n",
    "        doc_intel_connection_id=doc_intelligence_connection.id,\n",
    "        confidence_threshold=0.3,\n",
    "        min_length=15,\n",
    "        overlap_threshold=0.7,\n",
    "        ignore_roles=\"pageFooter,footnote,pageHeader\",\n",
    "        \n",
    "        # Chunk Caption Index params\n",
    "        azure_openai_connection_id=azure_openai_connection.id,\n",
    "        azure_search_connection_id=azure_search_connection.id,\n",
    "        embd_deployment_name=\"text-embedding-ada-002\",\n",
    "        vision_deployment_name=\"gpt-4v\",\n",
    "        index_name=\"myindex\",\n",
    "        \n",
    "        # Compute settings\n",
    "        analyzer_compute=\"hp-gpu-cluster\",\n",
    "        indexer_compute=\"cpu-cluster\"\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chunk_caption_index_component (0.02 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24636/24636 [00:00<00:00, 267211.98it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    }
   ],
   "source": [
    "pipeline = main(ml_client)\n",
    "\n",
    "# Submit the pipeline\n",
    "run = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"document-processing-pipeline\",\n",
    "    tags={\"type\": \"document-processing\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nougat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
