{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify this scientific image into one of the following categories:\n",
    "\n",
    "TABLES/CHARTS:\n",
    "- Data table\n",
    "- Statistical table\n",
    "- Comparison table\n",
    "\n",
    "GRAPHS/PLOTS:\n",
    "- Line graph\n",
    "- Bar chart\n",
    "- Scatter plot\n",
    "- Box plot\n",
    "- Histogram\n",
    "- Pie chart\n",
    "- Heat map\n",
    "- Network graph\n",
    "- Time series\n",
    "\n",
    "MICROSCOPY:\n",
    "- Light microscopy\n",
    "- Electron microscopy\n",
    "- Fluorescence microscopy\n",
    "- Confocal microscopy\n",
    "- Super-resolution microscopy\n",
    "\n",
    "SPECTROSCOPY:\n",
    "- Mass spectroscopy\n",
    "- NMR spectroscopy\n",
    "- IR spectroscopy\n",
    "- UV-vis spectroscopy\n",
    "- X-ray spectroscopy\n",
    "\n",
    "MEDICAL/BIOLOGICAL IMAGING:\n",
    "- X-ray\n",
    "- CT scan\n",
    "- MRI scan\n",
    "- Ultrasound\n",
    "- PET scan\n",
    "- Histology slide\n",
    "- Western blot\n",
    "- Gel electrophoresis\n",
    "\n",
    "DIAGRAMS/ILLUSTRATIONS:\n",
    "- Chemical structure\n",
    "- Molecular diagram\n",
    "- Anatomical illustration\n",
    "- Flowchart\n",
    "- Schematic diagram\n",
    "- Circuit diagram\n",
    "- Mechanical diagram\n",
    "- Process flow diagram\n",
    "\n",
    "MAPS/GEOGRAPHICAL:\n",
    "- Geographic map\n",
    "- GIS visualization\n",
    "- Satellite image\n",
    "- Terrain model\n",
    "\n",
    "MATHEMATICAL:\n",
    "- Equation\n",
    "- Mathematical model\n",
    "- Geometric figure\n",
    "- Mathematical plot\n",
    "\n",
    "COMPUTER-GENERATED:\n",
    "- 3D rendering\n",
    "- Simulation visualization\n",
    "- Computer model\n",
    "\n",
    "MISCELLANEOUS:\n",
    "- Field photograph\n",
    "- Sample photograph\n",
    "- Experimental setup\n",
    "- Equipment photograph\n",
    "- Screenshot\n",
    "- Logo/Institutional insignia\n",
    "- Cover art\n",
    "- Author photograph\n",
    "- Infographic\n",
    "- Conceptual illustration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CLASSIFICATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert image classifier specializing in scientific literature. Your task is to classify images from academic papers and research documents into precise numbered categories. Analyze each image carefully, considering its visual characteristics, content, and typical usage in scientific literature.\n",
    "\n",
    "Return your analysis as a valid JSON object with exactly this format:\n",
    "{\n",
    "  \"class\": int,\n",
    "  \"confidence\": float\n",
    "}\n",
    "\n",
    "Where \"class\" is the integer corresponding to the image category, and \"confidence\" is a number between 0.0 and 1.0 representing your confidence in the classification. Do not include any other fields in your response - only these two fields in this exact format.\n",
    "\"\"\"\n",
    "IMAGE_CLASSIFICATION_USER_PROMPT = \"\"\"\n",
    "Classify this scientific image into exactly one of the following numbered categories:\n",
    "\n",
    "1. Data table\n",
    "2. Statistical table\n",
    "3. Line graph\n",
    "4. Bar chart\n",
    "5. Scatter plot\n",
    "6. Box plot\n",
    "7. Histogram\n",
    "8. Pie chart\n",
    "9. Heat map\n",
    "10. Network graph\n",
    "11. Time series plot\n",
    "12. Light microscopy\n",
    "13. Electron microscopy\n",
    "14. Fluorescence microscopy\n",
    "15. Confocal microscopy\n",
    "16. Mass spectroscopy\n",
    "17. NMR spectroscopy\n",
    "18. IR spectroscopy\n",
    "19. UV-vis spectroscopy\n",
    "20. X-ray spectroscopy\n",
    "21. X-ray (medical)\n",
    "22. CT scan\n",
    "23. MRI scan\n",
    "24. Ultrasound\n",
    "25. PET scan\n",
    "26. Histology slide\n",
    "27. Western blot\n",
    "28. Gel electrophoresis\n",
    "29. Chemical structure\n",
    "30. Molecular diagram\n",
    "31. Anatomical illustration\n",
    "32. Flowchart\n",
    "33. Schematic diagram\n",
    "34. Circuit diagram\n",
    "35. Mechanical diagram\n",
    "36. Process flow diagram\n",
    "37. Geographic map\n",
    "38. GIS visualization\n",
    "39. Satellite image\n",
    "40. Equation/Mathematical expression\n",
    "41. Geometric figure\n",
    "42. 3D rendering\n",
    "43. Computer simulation\n",
    "44. Field photograph\n",
    "45. Sample photograph\n",
    "46. Experimental setup\n",
    "47. Equipment photograph\n",
    "48. Screenshot\n",
    "49. Logo/Institutional insignia\n",
    "50. Infographic\n",
    "51. other\n",
    "\n",
    "Return only a JSON with the class number (integer) and your confidence (float between 0.0 and 1.0) in this exact format:\n",
    "{\n",
    "  \"class\": int,\n",
    "  \"confidence\": float\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI, OpenAI\n",
    "from azureml.rag.utils.connections import get_connection_by_id_v2\n",
    "from azureml.rag.utils.logging import get_logger, safe_mlflow_start_run, track_activity\n",
    "import os\n",
    "\n",
    "logger = get_logger(\"document_analyzer\")\n",
    "\n",
    "def setup_openai_client(connection_id: str, type: str = \"openai\"):\n",
    "    \"\"\"Set up Azure OpenAI client using connection.\"\"\"\n",
    "    try:\n",
    "        # Get connection details\n",
    "        connection = get_connection_by_id_v2(connection_id)\n",
    "\n",
    "        # Safely access endpoint and api_key from dictionary\n",
    "        if connection.endpoint is not None:\n",
    "            endpoint = connection.endpoint\n",
    "        else:\n",
    "            endpoint = connection.get(\"endpoint\") or connection.get(\"properties\", {}).get(\"metadata\", {}).get(\"endpoint\")\n",
    "        if connection.api_key is not None:\n",
    "            api_key = connection.api_key\n",
    "        else:\n",
    "            api_key = connection.get(\"api_key\") or connection.get(\"properties\", {}).get(\"credentials\", {}).get(\"keys\", {}).get(\"api_key\")\n",
    "\n",
    "        if not endpoint or not api_key:\n",
    "            raise ValueError(\"Missing endpoint or api_key in connection details.\")\n",
    "\n",
    "        if type == \"openai\":\n",
    "            # Create client for openai\n",
    "            client = OpenAI(\n",
    "                api_key=api_key,\n",
    "                base_url=endpoint\n",
    "            )\n",
    "        else:                \n",
    "            # Create client for  vision\n",
    "            client = AzureOpenAI(\n",
    "                api_key=api_key,\n",
    "                api_version=\"2025-01-01-preview\",\n",
    "                azure_endpoint=endpoint\n",
    "            )\n",
    "\n",
    "        return client\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to setup Azure OpenAI connection: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# Example of registering the component in a workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_connection_name = \"open_ai_connection_01\"\n",
    "# aoai_connection_name = \"deepseek\"\n",
    "acs_connection_name = \"acs-connection\"\n",
    "data_set_name = \"papers\"\n",
    "asset_name = \"aoai_acs_mlindex\"\n",
    "doc_intelligence_connection_name = \"doc-intelligence-connection\"\n",
    "vision_deploy_name = \"gpt-4o\"\n",
    "aoai_embedding_model_name = \"text-embedding-3-large\"\n",
    "\n",
    "acs_config = {\n",
    "    \"index_name\": \"qknows-embedding\",\n",
    "}\n",
    "\n",
    "experiment_name = \"sample-acs-embedding\"\n",
    "\n",
    "aoai_connection_id = ml_client.connections.get(aoai_connection_name).id\n",
    "\n",
    "aoai_cleint = setup_openai_client(aoai_connection_id, \"azure-openai\")\n",
    "\n",
    "# Define your deployment name for the vision model (e.g., \"gpt-4v\")\n",
    "vision_deployment_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ai-deepseektest505679245816600.openai.azure.com/openai/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = aoai_cleint.base_url\n",
    "str(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_completion = aoai_cleint.chat.completions.create(\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Say this is a test\",\n",
    "#         }\n",
    "#     ],\n",
    "#     model=\"deepseek-r\",\n",
    "# )\n",
    "\n",
    "# print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_model_info(\n",
    "#     model_name=\"gpt-4o\",\n",
    "#     deployment_name=vision_deployment_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(404) Resource not found\nCode: 404\nMessage: Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m client \u001b[38;5;241m=\u001b[39m ChatCompletionsClient(\n\u001b[1;32m     13\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m     14\u001b[0m     credential\u001b[38;5;241m=\u001b[39mDefaultAzureCredential(),\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mUserMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI am going to Paris, what should I see?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/ai/inference/_patch.py:737\u001b[0m, in \u001b[0;36mChatCompletionsClient.complete\u001b[0;34m(self, body, messages, stream, frequency_penalty, presence_penalty, temperature, top_p, max_tokens, response_format, stop, tools, tool_choice, seed, model, model_extras, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[1;32m    736\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# Load the body in memory and close the socket\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azure/core/exceptions.py:161\u001b[0m, in \u001b[0;36mmap_error\u001b[0;34m(status_code, response, error_map)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    160\u001b[0m error \u001b[38;5;241m=\u001b[39m error_type(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mResourceNotFoundError\u001b[0m: (404) Resource not found\nCode: 404\nMessage: Resource not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "url = \"https://ai-deepseektest505679245816600.openai.azure.com/\"\n",
    "api_key = aoai_cleint.api_key\n",
    "\n",
    "endpoint = str(url)\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        UserMessage(content=\"I am going to Paris, what should I see?\"),\n",
    "    ],\n",
    "    max_tokens=4096,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The **Eiffel Tower** is often considered the crown jewel of Paris and one of the most famous landmarks in the world. Its greatness comes from several aspects:\n",
      "\n",
      "### 1. **Iconic Symbol of Paris and France**  \n",
      "   - When people think of Paris, the Eiffel Tower is usually the first thing that comes to mind. It’s a universal symbol of romance, elegance, and the city’s artistic and architectural achievements.\n",
      "\n",
      "### 2. **Unique Architectural Design**\n",
      "   - Designed by engineer **Gustave Eiffel**, the tower is a masterpiece of iron artistry and engineering. Built for the **1889 Exposition Universelle (World’s Fair)** to celebrate the 100th anniversary of the French Revolution, its revolutionary design was initially controversial but later became beloved worldwide.\n",
      "   - At its completion, the Eiffel Tower was the **tallest man-made structure in the world** (standing at 330 meters/1,083 feet today with antennas).\n",
      "\n",
      "### 3. **Incredible Views**\n",
      "   - Visitors can take an elevator or climb the stairs to one of three levels for stunning panoramic views of Paris. Whether you go to the **second floor** or the **top floor**, you'll be treated to breathtaking vistas of landmarks such as the **Seine River**, **Notre-Dame**, **Sacré-Cœur**, and beyond.\n",
      "\n",
      "### 4. **A Historical and Cultural Touchstone**\n",
      "   - It's been featured in countless books, films, and photographs, becoming a global icon of innovation and French culture. The Eiffel Tower represents history and a modern Paris simultaneously.\n",
      "   - During WW2, the lifts were disabled to prevent Nazi troops from easily reaching the summit—a fascinating tidbit from its history.\n",
      "\n",
      "### 5. **Nighttime Magic**\n",
      "   - At night, the tower is illuminated with thousands of twinkling lights during its hourly light shows, creating a magical and romantic atmosphere. This dazzling scene is one of the most enchanting experiences in Paris.\n",
      "\n",
      "### 6. **Versatile Experiences**\n",
      "   - You can enjoy fine dining at restaurants like **Le 58 Tour Eiffel** or ***Le Jules Verne,* a Michelin-starred establishment**, located within the tower. There's also a champagne bar at the top to toast your Parisian adventure.\n",
      "\n",
      "### 7. **Setting for Memorable Moments**\n",
      "   - From proposals to iconic photographs, visiting the Eiffel Tower is an unforgettable experience for millions of travelers. Standing under or atop the steel monument creates a moment you'll cherish forever.\n",
      "\n",
      "The Eiffel Tower’s mix of artistic beauty, historical significance, romantic charm, and functionality makes it **\"so great\"**—and the ultimate Parisian experience! You’ll feel its magic when you stand beneath it or gaze up at its magnificent structure.\n",
      "Model: gpt-4o-2024-11-20\n",
      "Usage:\n",
      "\tPrompt tokens: 202\n",
      "\tTotal tokens: 752\n",
      "\tCompletion tokens: 550\n"
     ]
    }
   ],
   "source": [
    "# pip install azure-ai-inference\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "connection = get_connection_by_id_v2(aoai_connection_id)\n",
    "\n",
    "# Safely access endpoint and api_key from dictionary\n",
    "if connection.endpoint is not None:\n",
    "    endpoint = connection.endpoint\n",
    "else:\n",
    "    endpoint = connection.get(\"endpoint\") or connection.get(\"properties\", {}).get(\"metadata\", {}).get(\"endpoint\")\n",
    "if connection.api_key is not None:\n",
    "    api_key = connection.api_key\n",
    "else:\n",
    "    api_key = connection.get(\"api_key\") or connection.get(\"properties\", {}).get(\"credentials\", {}).get(\"keys\", {}).get(\"api_key\")\n",
    "\n",
    "endpoint = \"https://ai-deepseektest505679245816600.openai.azure.com/openai/deployments/gpt-4o\"\n",
    "\n",
    "if not api_key:\n",
    "  raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    api_version=\"2024-06-01\",\n",
    ")\n",
    "\n",
    "# model_info = client.get_model_info()\n",
    "# print(\"Model name:\", model_info.model_name)\n",
    "# print(\"Model type:\", model_info.model_type)\n",
    "# print(\"Model provider name:\", model_info.model_provider_name)\n",
    "\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"I am going to Paris, what should I see?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Paris, the capital of France, is known for its stunning architecture, art museums, historical landmarks, and romantic atmosphere. Here are some of the top attractions to see in Paris:\\n\\n1. The Eiffel Tower: The iconic Eiffel Tower is one of the most recognizable landmarks in the world and offers breathtaking views of the city.\\n2. The Louvre Museum: The Louvre is one of the world's largest and most famous museums, housing an impressive collection of art and artifacts, including the Mona Lisa.\\n3. Notre-Dame Cathedral: This beautiful cathedral is one of the most famous landmarks in Paris and is known for its Gothic architecture and stunning stained glass windows.\\n\\nThese are just a few of the many attractions that Paris has to offer. With so much to see and do, it's no wonder that Paris is one of the most popular tourist destinations in the world.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What is so great about #1?\"\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 2048\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "print(\"Response:\", response.choices[0].message.content)\n",
    "print(\"Model:\", response.model)\n",
    "print(\"Usage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../aml_pipeline/chuck_caption_component/')\n",
    "# enhanced_doc_analyzer_component/enhanced_document_analyzer\n",
    "\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "from src import DocumentProcessor\n",
    "from src.prompt import IMAGE_CLASSIFICATION_SYSTEM_PROMPT, IMAGE_CLASSIFICATION_USER_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class ImageClassification(DocumentProcessor):\n",
    "    def __init__(self, input_folder, output_folder, openai_client, vision_deployment_name):\n",
    "        super().__init__(input_folder, output_folder, openai_client, vision_deployment_name)\n",
    "        self.vision_client = openai_client\n",
    "        self.vision_deployment_name = vision_deployment_name\n",
    "    \n",
    "    def get_image_classification(self, image_path):\n",
    "        try:\n",
    "            # Get base64 encoded image\n",
    "            base64_image = self.encode_image(image_path)\n",
    "            if not base64_image:\n",
    "                print(f\"Skipping classification for invalid image: {image_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Create ChatCompletionsClient with connection information\n",
    "            connection = get_connection_by_id_v2(aoai_connection_id)\n",
    "            \n",
    "            # Safely access endpoint and api_key from dictionary\n",
    "            if connection.endpoint is not None:\n",
    "                endpoint = connection.endpoint\n",
    "            else:\n",
    "                endpoint = connection.get(\"endpoint\") or connection.get(\"properties\", {}).get(\"metadata\", {}).get(\"endpoint\")\n",
    "            if connection.api_key is not None:\n",
    "                api_key = connection.api_key\n",
    "            else:\n",
    "                api_key = connection.get(\"api_key\") or connection.get(\"properties\", {}).get(\"credentials\", {}).get(\"keys\", {}).get(\"api_key\")\n",
    "            \n",
    "            # Create endpoint URL with deployment name\n",
    "            endpoint_url = f\"{endpoint}/openai/deployments/{self.vision_deployment_name}\"\n",
    "            \n",
    "            # Create chat client\n",
    "            client = ChatCompletionsClient(\n",
    "                endpoint=endpoint_url,\n",
    "                credential=AzureKeyCredential(api_key),\n",
    "                api_version=\"2025-01-01-preview\"\n",
    "            )\n",
    "            \n",
    "            max_retries = 3\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    # Create the payload with system and user messages\n",
    "                    payload = {\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": IMAGE_CLASSIFICATION_SYSTEM_PROMPT\n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": [\n",
    "                                    {\n",
    "                                        \"type\": \"text\",\n",
    "                                        \"text\": IMAGE_CLASSIFICATION_USER_PROMPT\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"type\": \"image_url\",\n",
    "                                        \"image_url\": {\n",
    "                                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                        }\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        ],\n",
    "                        \"temperature\": 0.0,\n",
    "                        \"max_tokens\": 100,\n",
    "                        \"response_format\": {\"type\": \"json_object\"}\n",
    "                    }\n",
    "                    \n",
    "                    # Call the API\n",
    "                    response = client.complete(payload)\n",
    "\n",
    "                    print(\"Model:\", response.model)\n",
    "                    print(\"Usage:\")\n",
    "                    print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "                    print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "                    print(\"\tCompletion tokens:\", response.usage.completion_tokens)\n",
    "\n",
    "\n",
    "                    # Extract the JSON response\n",
    "                    result = json.loads(response.choices[0].message.content)\n",
    "                    return result\n",
    "                    \n",
    "                except json.JSONDecodeError:\n",
    "                    # If the response isn't valid JSON, try to extract JSON from the text\n",
    "                    content = response.choices[0].message.content\n",
    "                    try:\n",
    "                        # Try to find JSON within the response\n",
    "                        json_start = content.find('{')\n",
    "                        json_end = content.rfind('}') + 1\n",
    "                        if json_start >= 0 and json_end > json_start:\n",
    "                            json_str = content[json_start:json_end]\n",
    "                            return json.loads(json_str)\n",
    "                        else:\n",
    "                            print(f\"Could not extract JSON from response: {content}\")\n",
    "                            if attempt < max_retries - 1:\n",
    "                                continue\n",
    "                            return None\n",
    "                    except Exception as json_extract_err:\n",
    "                        print(f\"Failed to parse JSON response: {str(json_extract_err)}\")\n",
    "                        if attempt < max_retries - 1:\n",
    "                            continue\n",
    "                        return None\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Image classification attempt {attempt + 1} failed: {str(e)}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(f\"All image classification attempts failed for {image_path}\")\n",
    "                        return None\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Image classification failed: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 07:28:56,448 - src.document_processor - INFO - Input folder: /home/azureuser/academic-document-analyzer/docs\n",
      "2025-03-09 07:28:56,449 - src.document_processor - INFO - Output folder: .\n",
      "2025-03-09 07:28:56,450 - src.document_processor - INFO - Successfully initialized tiktoken tokenizer\n",
      "Model: gpt-4o-2024-11-20\n",
      "Usage:\n",
      "\tPrompt tokens: 1004\n",
      "\tTotal tokens: 1025\n",
      "\tCompletion tokens: 21\n",
      "Image classified as: Flowchart (ID: 32)\n",
      "Confidence: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Initialize the image classification service\n",
    "classifier = ImageClassification(\n",
    "    input_folder= \"/home/azureuser/academic-document-analyzer/docs/\",\n",
    "    output_folder= \".\",\n",
    "    openai_client=aoai_cleint,\n",
    "    vision_deployment_name=vision_deployment_name\n",
    ")\n",
    "\n",
    "# Path to the image you want to classify\n",
    "image_path = \"/home/azureuser/academic-document-analyzer/docs/indexer_pipeline-next-step.png\"\n",
    "\n",
    "# Classify the image\n",
    "result = classifier.get_image_classification(image_path)\n",
    "\n",
    "# Process the result\n",
    "if result:\n",
    "    class_id = result[\"image_class\"]\n",
    "    confidence = result[\"probability_score\"]\n",
    "    \n",
    "    # Map class ID to class name (you would have this mapping defined somewhere)\n",
    "    class_names = {\n",
    "        1: \"Data table\",\n",
    "        2: \"Statistical table\",\n",
    "        3: \"Line graph\",\n",
    "        4: \"Bar chart\",\n",
    "        5: \"Scatter plot\",\n",
    "        6: \"Box plot\",\n",
    "        7: \"Histogram\",\n",
    "        8: \"Pie chart\",\n",
    "        9: \"Heat map\",\n",
    "        10: \"Network graph\",                \n",
    "        11: \"Time series plot\",\n",
    "        12: \"Light microscopy\",\n",
    "        13: \"Electron microscopy\",\n",
    "        14: \"Fluorescence microscopy\",\n",
    "        15: \"Confocal microscopy\",\n",
    "        16: \"Mass spectroscopy\",\n",
    "        17: \"NMR spectroscopy\",\n",
    "        18: \"IR spectroscopy\",\n",
    "        19: \"UV-vis spectroscopy\",\n",
    "        20: \"X-ray spectroscopy\",\n",
    "        21: \"X-ray (medical)\",\n",
    "        22: \"CT scan\",\n",
    "        23: \"MRI scan\",\n",
    "        24: \"Ultrasound\",\n",
    "        25: \"PET scan\",\n",
    "        26: \"Histology slide\",\n",
    "        27: \"Western blot\",\n",
    "        28: \"Gel electrophoresis\",\n",
    "        29: \"Chemical structure\",\n",
    "        30: \"Molecular diagram\",\n",
    "        31: \"Anatomical illustration\",\n",
    "        32: \"Flowchart\",\n",
    "        33: \"Schematic diagram\",\n",
    "        34: \"Circuit diagram\",\n",
    "        35: \"Mechanical diagram\",\n",
    "        36: \"Process flow diagram\",\n",
    "        37: \"Geographic map\",\n",
    "        38: \"GIS visualization\",    \n",
    "        39: \"Satellite image\",\n",
    "        40: \"Equation/Mathematical expression\",\n",
    "        41: \"Geometric figure\",\n",
    "        42: \"3D rendering\",     \n",
    "        43: \"Computer simulation\",\n",
    "        44: \"Field photograph\",\n",
    "        45: \"Sample photograph\",\n",
    "        46: \"Experimental setup\",\n",
    "        47: \"Equipment photograph\",\n",
    "        48: \"Screenshot\",\n",
    "        49: \"Logo/Institutional insignia\",\n",
    "        50: \"Infographic\",\n",
    "        51: \"other\"\n",
    "    }\n",
    "    \n",
    "    class_name = class_names.get(class_id, \"Unknown class\")\n",
    "    \n",
    "    print(f\"Image classified as: {class_name} (ID: {class_id})\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "else:\n",
    "    print(\"Classification failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
