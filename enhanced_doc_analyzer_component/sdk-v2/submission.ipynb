{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import CommandComponent, Environment, BuildContext\n",
    "from pathlib import Path\n",
    "\n",
    "def create_doc_analyzer_component(\n",
    "    environment_image: str = \"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:18\",\n",
    "    conda_file: str = \"../conda.yaml\"\n",
    ") -> CommandComponent:\n",
    "    \"\"\"\n",
    "    Create the document analyzer component using Azure ML SDK v2.\n",
    "    \n",
    "    Args:\n",
    "        environment_image: Docker image to use for the environment\n",
    "        conda_file: Path to conda environment file\n",
    "        \n",
    "    Returns:\n",
    "        CommandComponent: The defined component\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the environment\n",
    "    env = Environment(\n",
    "        build=BuildContext(path=\"./docker\"),\n",
    "        name=\"doc-analyzer-env\",\n",
    "        description=\"Custom Environment for Document Analyzer\",\n",
    "    )\n",
    "    \n",
    "    return CommandComponent(\n",
    "        name=\"document_analyzer\",\n",
    "        display_name=\"Document Analyzer\",\n",
    "        # version=\"6\",\n",
    "        description=\"Analyzes multiple PDF documents using Azure Document Intelligence and local processing\",\n",
    "        \n",
    "        # Define inputs\n",
    "        inputs={\n",
    "            \"input_folder\": {\n",
    "                \"type\": \"uri_folder\",\n",
    "                \"description\": \"Input folder containing PDF files\"\n",
    "            },\n",
    "            \"doc_intel_connection_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Azure ML connection ID for Document Intelligence\"\n",
    "            },\n",
    "            \"confidence_threshold\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 0.7,\n",
    "                \"description\": \"Confidence threshold for element detection\"\n",
    "            },\n",
    "            \"min_length\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"default\": 10,\n",
    "                \"description\": \"Minimum text length to consider\"\n",
    "            },\n",
    "            \"overlap_threshold\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 0.5,\n",
    "                \"description\": \"Threshold for overlap detection\"\n",
    "            },\n",
    "            \"ignore_roles\": {\n",
    "                \"type\": \"string\",\n",
    "                \"default\": \"pageFooter,footnote\",\n",
    "                \"description\": \"Comma-separated list of roles to ignore\"\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # Define outputs\n",
    "        outputs={\n",
    "            \"output_dir\": {\n",
    "                \"type\": \"uri_folder\",\n",
    "                \"description\": \"Folder containing visualization images organized by PDF\"\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # Define environment\n",
    "        environment=env,\n",
    "        \n",
    "        # Define code and command\n",
    "        code=\"../\",\n",
    "        command=\"python run.py --input_folder ${{inputs.input_folder}} --doc_intel_connection_id ${{inputs.doc_intel_connection_id}} --confidence_threshold ${{inputs.confidence_threshold}} --min_length ${{inputs.min_length}} --overlap_threshold ${{inputs.overlap_threshold}} --ignore_roles ${{inputs.ignore_roles}} --output_dir ${{outputs.output_dir}}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# Example of registering the component in a workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the component\n",
    "# ml_client.components.create_or_update(create_doc_analyzer_component())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .. to sys.path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Pipeline, Data\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "def create_document_analysis_pipeline(\n",
    "    pdf_folder: str,\n",
    "    doc_intel_connection_id: str,\n",
    "    confidence_threshold: float = 0.5,\n",
    "    min_length: int = 10,\n",
    "    overlap_threshold: float = 0.5,\n",
    "    ignore_roles: str = \"pageFooter,footnote,pageHeader\",\n",
    "    compute_name: str = \"cpu-cluster\"\n",
    ") -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a pipeline for document analysis.\n",
    "    \n",
    "    Args:\n",
    "        pdf_folder: Path or reference to the input folder containing PDFs\n",
    "        doc_intel_connection_id: Azure ML connection ID for Document Intelligence\n",
    "        compute_name: Name of the compute target to use\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline: The defined pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    @dsl.pipeline(\n",
    "        description=\"Document analysis pipeline\",\n",
    "        default_compute=compute_name\n",
    "    )\n",
    "    def doc_analysis_pipeline():\n",
    "        # Get the document analyzer component\n",
    "        analyzer_component = create_doc_analyzer_component()\n",
    "        \n",
    "        # Define the analysis job\n",
    "        analysis_job = analyzer_component(\n",
    "            input_folder=Input(type=\"uri_folder\", path=pdf_folder),\n",
    "            doc_intel_connection_id=doc_intel_connection_id,\n",
    "            # Optional: Override default parameters\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            min_length=min_length,\n",
    "            overlap_threshold=overlap_threshold,\n",
    "            ignore_roles=ignore_roles\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"output_dir\": analysis_job.outputs.output_dir,\n",
    "        }\n",
    "    \n",
    "    # Return the pipeline object by calling the pipeline function\n",
    "    return doc_analysis_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Warning: the provided asset name 'doc-analyzer-env' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'doc-analyzer-env' will not be used for anonymous registration\n",
      "\u001b[32mUploading enhanced_doc_analyzer_component (0.12 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 115982/115982 [00:00<00:00, 559466.28it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: epic_lettuce_z1zfxtyy5m\n",
      "Web View: https://ml.azure.com/runs/epic_lettuce_z1zfxtyy5m?wsid=/subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourcegroups/rg-airesearcher-dev-01/workspaces/mlw-airesearcher-dev-01\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2025-02-07 10:24:57Z] Submitting 1 runs, first five are: bd537f61:c396afeb-5dc6-454f-8006-26337abfe6ac\n",
      "[2025-02-07 10:47:40Z] Completing processing run id c396afeb-5dc6-454f-8006-26337abfe6ac.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: epic_lettuce_z1zfxtyy5m\n",
      "Web View: https://ml.azure.com/runs/epic_lettuce_z1zfxtyy5m?wsid=/subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourcegroups/rg-airesearcher-dev-01/workspaces/mlw-airesearcher-dev-01\n",
      "\n",
      "\n",
      "Pipeline outputs:\n",
      "Output folder: ${{parent.outputs.output_dir}}\n",
      "Combined elements data: ${{parent.outputs.combined_elements_data}}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Pipeline, Data\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "doc_intelligence_connection = ml_client.connections.get(\"my-doc-intelligence-connection\")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = create_document_analysis_pipeline(\n",
    "    pdf_folder=\"azureml:raw_papers:1\",\n",
    "    doc_intel_connection_id=doc_intelligence_connection.id,  # Your connection ID\n",
    "    compute_name=\"hp-gpu-cluster\",\n",
    "    confidence_threshold=0.2,\n",
    "    min_length=15,\n",
    "    overlap_threshold=0.7,\n",
    "    ignore_roles=\"pageFooter,footnote,pageHeader\"\n",
    ")\n",
    "\n",
    "# Submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"document-analysis\",\n",
    ")\n",
    "\n",
    "# Wait for the job to complete\n",
    "ml_client.jobs.stream(pipeline_job.name)\n",
    "\n",
    "# Get the outputs\n",
    "job_outputs = ml_client.jobs.get(pipeline_job.name).outputs\n",
    "\n",
    "print(\"\\nPipeline outputs:\")\n",
    "print(f\"Output folder: {job_outputs['output_dir']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nougat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
