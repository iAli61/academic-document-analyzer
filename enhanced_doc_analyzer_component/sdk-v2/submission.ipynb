{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import CommandComponent, Environment, BuildContext\n",
    "from pathlib import Path\n",
    "\n",
    "def create_doc_analyzer_component(\n",
    "    environment_image: str = \"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:18\",\n",
    "    conda_file: str = \"../conda.yaml\"\n",
    ") -> CommandComponent:\n",
    "    \"\"\"\n",
    "    Create the document analyzer component using Azure ML SDK v2.\n",
    "    \n",
    "    Args:\n",
    "        environment_image: Docker image to use for the environment\n",
    "        conda_file: Path to conda environment file\n",
    "        \n",
    "    Returns:\n",
    "        CommandComponent: The defined component\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the environment\n",
    "    env = Environment(\n",
    "        build=BuildContext(path=\"./docker\"),\n",
    "        name=\"doc-analyzer-env\",\n",
    "        description=\"Custom Environment for Document Analyzer\",\n",
    "    )\n",
    "    \n",
    "    return CommandComponent(\n",
    "        name=\"document_analyzer\",\n",
    "        display_name=\"Document Analyzer\",\n",
    "        version=\"5\",\n",
    "        description=\"Analyzes multiple PDF documents using Azure Document Intelligence and local processing\",\n",
    "        \n",
    "        # Define inputs\n",
    "        inputs={\n",
    "            \"input_folder\": {\n",
    "                \"type\": \"uri_folder\",\n",
    "                \"description\": \"Input folder containing PDF files\"\n",
    "            },\n",
    "            \"doc_intel_connection_id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Azure ML connection ID for Document Intelligence\"\n",
    "            },\n",
    "            \"confidence_threshold\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 0.7,\n",
    "                \"description\": \"Confidence threshold for element detection\"\n",
    "            },\n",
    "            \"min_length\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"default\": 10,\n",
    "                \"description\": \"Minimum text length to consider\"\n",
    "            },\n",
    "            \"overlap_threshold\": {\n",
    "                \"type\": \"number\",\n",
    "                \"default\": 0.5,\n",
    "                \"description\": \"Threshold for overlap detection\"\n",
    "            },\n",
    "            \"ignore_roles\": {\n",
    "                \"type\": \"string\",\n",
    "                \"default\": \"pageFooter,footnote\",\n",
    "                \"description\": \"Comma-separated list of roles to ignore\"\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # Define outputs\n",
    "        outputs={\n",
    "            \"markdown_output_folder\": {\n",
    "                \"type\": \"uri_folder\",\n",
    "                \"description\": \"Folder containing markdown files for each processed PDF\"\n",
    "            },\n",
    "            \"combined_elements_data\": {\n",
    "                \"type\": \"uri_file\",\n",
    "                \"description\": \"CSV file containing combined elements data from all PDFs\"\n",
    "            },\n",
    "            \"visualizations_folder\": {\n",
    "                \"type\": \"uri_folder\",\n",
    "                \"description\": \"Folder containing visualization images organized by PDF\"\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        # Define environment\n",
    "        environment=env,\n",
    "        \n",
    "        # Define code and command\n",
    "        code=\"../\",\n",
    "        command=\"\"\"\n",
    "        python run.py \n",
    "        --input_folder ${{inputs.input_folder}} \n",
    "        --doc_intel_connection_id ${{inputs.doc_intel_connection_id}}\n",
    "        --confidence_threshold ${{inputs.confidence_threshold}} \n",
    "        --min_length ${{inputs.min_length}} \n",
    "        --overlap_threshold ${{inputs.overlap_threshold}} \n",
    "        --ignore_roles ${{inputs.ignore_roles}} \n",
    "        --markdown_output_folder ${{outputs.markdown_output_folder}} \n",
    "        --combined_elements_data ${{outputs.combined_elements_data}} \n",
    "        --visualizations_folder ${{outputs.visualizations_folder}}\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# Example of registering the component in a workspace\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Get workspace\n",
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the component\n",
    "# ml_client.components.create_or_update(create_doc_analyzer_component())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add .. to sys.path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Pipeline, Data\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "def create_document_analysis_pipeline(\n",
    "    pdf_folder: str,\n",
    "    doc_intel_connection_id: str,\n",
    "    compute_name: str = \"cpu-cluster\"\n",
    ") -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a pipeline for document analysis.\n",
    "    \n",
    "    Args:\n",
    "        pdf_folder: Path or reference to the input folder containing PDFs\n",
    "        doc_intel_connection_id: Azure ML connection ID for Document Intelligence\n",
    "        compute_name: Name of the compute target to use\n",
    "        \n",
    "    Returns:\n",
    "        Pipeline: The defined pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    @dsl.pipeline(\n",
    "        description=\"Document analysis pipeline\",\n",
    "        default_compute=compute_name\n",
    "    )\n",
    "    def doc_analysis_pipeline():\n",
    "        # Get the document analyzer component\n",
    "        analyzer_component = create_doc_analyzer_component()\n",
    "        \n",
    "        # Define the analysis job\n",
    "        analysis_job = analyzer_component(\n",
    "            input_folder=Input(type=\"uri_folder\", path=pdf_folder),\n",
    "            doc_intel_connection_id=doc_intel_connection_id,\n",
    "            # Optional: Override default parameters\n",
    "            confidence_threshold=0.8,\n",
    "            min_length=15,\n",
    "            overlap_threshold=0.6,\n",
    "            ignore_roles=\"pageFooter,footnote,pageHeader\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"markdown_output_folder\": analysis_job.outputs.markdown_output_folder,\n",
    "            \"combined_elements_data\": analysis_job.outputs.combined_elements_data,\n",
    "            \"visualizations_folder\": analysis_job.outputs.visualizations_folder\n",
    "        }\n",
    "    \n",
    "    # Return the pipeline object by calling the pipeline function\n",
    "    return doc_analysis_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading enhanced_doc_analyzer_component (0.11 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109095/109095 [00:00<00:00, 821260.48it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFileJobOutput'> and will be ignored\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: jolly_button_vzlbrlwbss\n",
      "Web View: https://ml.azure.com/runs/jolly_button_vzlbrlwbss?wsid=/subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourcegroups/rg-airesearcher-dev-01/workspaces/mlw-airesearcher-dev-01\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2025-02-05 16:02:28Z] Submitting 1 runs, first five are: 681d6a1c:31a5ec01-0701-4074-a8c9-933ce20747a5\n",
      "[2025-02-05 16:57:46Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: jolly_button_vzlbrlwbss\n",
      "Web View: https://ml.azure.com/runs/jolly_button_vzlbrlwbss?wsid=/subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourcegroups/rg-airesearcher-dev-01/workspaces/mlw-airesearcher-dev-01\n"
     ]
    },
    {
     "ename": "JobException",
     "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /analysis_job. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"swedencentral\",\n    \"location\": \"swedencentral\",\n    \"time\": \"2025-02-05T16:57:46.275788Z\",\n    \"component_name\": \"\"\n} ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mcreate_or_update(\n\u001b[1;32m     15\u001b[0m     pipeline,\n\u001b[1;32m     16\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Wait for the job to complete\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Get the outputs\u001b[39;00m\n\u001b[1;32m     23\u001b[0m job_outputs \u001b[38;5;241m=\u001b[39m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mget(pipeline_job\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m/anaconda/envs/nougat/lib/python3.9/site-packages/azure/core/tracing/decorator.py:116\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m func_tracing_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    115\u001b[0m     span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/nougat/lib/python3.9/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "File \u001b[0;32m/anaconda/envs/nougat/lib/python3.9/site-packages/azure/ai/ml/operations/_job_operations.py:844\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[38;5;241m=\u001b[39mjob_object\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m--> 844\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/nougat/lib/python3.9/site-packages/azure/ai/ml/operations/_job_ops_helper.py:334\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[0;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[1;32m    332\u001b[0m         file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    335\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException : \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)),\n\u001b[1;32m    336\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    337\u001b[0m             no_personal_data_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException raised on failed job.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m             error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    341\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    342\u001b[0m file_handle\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /analysis_job. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"swedencentral\",\n    \"location\": \"swedencentral\",\n    \"time\": \"2025-02-05T16:57:46.275788Z\",\n    \"component_name\": \"\"\n} "
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient, dsl, Input, Output\n",
    "from azure.ai.ml.entities import Pipeline, Data\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = create_document_analysis_pipeline(\n",
    "    pdf_folder=\"azureml:raw_papers:1\",\n",
    "    doc_intel_connection_id=\"my-doc-intelligence-connection\",  # Your connection ID\n",
    "    compute_name=\"hp-gpu-cluster\"\n",
    ")\n",
    "\n",
    "# Submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"document-analysis\",\n",
    ")\n",
    "\n",
    "# Wait for the job to complete\n",
    "ml_client.jobs.stream(pipeline_job.name)\n",
    "\n",
    "# Get the outputs\n",
    "job_outputs = ml_client.jobs.get(pipeline_job.name).outputs\n",
    "\n",
    "print(\"\\nPipeline outputs:\")\n",
    "print(f\"Markdown output folder: {job_outputs['markdown_output_folder']}\")\n",
    "print(f\"Combined elements data: {job_outputs['combined_elements_data']}\")\n",
    "print(f\"Visualizations folder: {job_outputs['visualizations_folder']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nougat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
