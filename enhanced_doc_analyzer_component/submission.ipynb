{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n"
     ]
    }
   ],
   "source": [
    "ml_client = MLClient.from_config(\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:18', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-academic-documents-analyser', 'description': 'Environment for the Academic Documents Analyser', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/f804f2da-c27b-45ac-bf80-16d4d331776d/resourceGroups/rg-airesearcher-dev-01/providers/Microsoft.MachineLearningServices/workspaces/mlw-airesearcher-dev-01/environments/docker-academic-documents-analyser/versions/1', 'Resource__source_path': '', 'base_path': '/home/alibina/repo/academic-document-analyzer', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f23f8534820>, 'serialize': <msrest.serialization.Serializer object at 0x7f23f8534d00>, 'version': '1', 'conda_file': {'channels': ['conda-forge', 'defaults'], 'dependencies': ['python=3.11', 'pytorch', 'transformers', 'pip', {'pip': ['nougat-ocr', 'azure-ai-ml==1.23.0', 'marshmallow==3.19.0', 'pillow', 'azure-ai-formrecognizer', 'pandas', 'numpy', 'azureml-rag>=0.2.2']}], 'name': 'doc-analysis'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\",\\n    \"defaults\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.11\",\\n    \"pytorch\",\\n    \"transformers\",\\n    \"pip\",\\n    {\\n      \"pip\": [\\n        \"nougat-ocr\",\\n        \"azure-ai-ml==1.23.0\",\\n        \"marshmallow==3.19.0\",\\n        \"pillow\",\\n        \"azure-ai-formrecognizer\",\\n        \"pandas\",\\n        \"numpy\",\\n        \"azureml-rag>=0.2.2\"\\n      ]\\n    }\\n  ],\\n  \"name\": \"doc-analysis\"\\n}'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:18\",\n",
    "    conda_file=\"enviroment/conda.yaml\",\n",
    "    name=\"docker-academic-documents-analyser\",\n",
    "    description=\"Environment for the Academic Documents Analyser\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import Component, Environment, Command\n",
    "from src import EnhancedDocumentAnalyzer\n",
    "\n",
    "def init_component():\n",
    "    \"\"\"Initialize the Enhanced Document Analyzer component.\"\"\"\n",
    "    \n",
    "    # Define the component\n",
    "    component = Component(\n",
    "        name=\"enhanced_document_analyzer\",\n",
    "        display_name=\"Enhanced Document Analyzer\",\n",
    "        version=\"1.0.0\",\n",
    "        description=\"Analyzes PDF documents using Azure Document Intelligence and local layout detection\",\n",
    "        tags={\"category\": \"Document Processing\"},\n",
    "        \n",
    "        # Define inputs\n",
    "        inputs={\n",
    "            \"input_pdf\": Input(type=\"uri_file\", description=\"Input PDF file to analyze\"),\n",
    "            \"azure_api_key\": Input(type=\"string\", description=\"Azure Document Intelligence API key\"),\n",
    "            \"azure_endpoint\": Input(type=\"string\", description=\"Azure Document Intelligence endpoint\"),\n",
    "            \"confidence_threshold\": Input(\n",
    "                type=\"number\", \n",
    "                default=0.7,\n",
    "                description=\"Confidence threshold for element detection\"\n",
    "            ),\n",
    "            \"min_length\": Input(\n",
    "                type=\"integer\",\n",
    "                default=10,\n",
    "                description=\"Minimum text length to consider\"\n",
    "            ),\n",
    "            \"overlap_threshold\": Input(\n",
    "                type=\"number\",\n",
    "                default=0.5,\n",
    "                description=\"Threshold for overlap detection\"\n",
    "            ),\n",
    "            \"ignore_roles\": Input(\n",
    "                type=\"string\",\n",
    "                default=\"pageFooter,footnote\",\n",
    "                description=\"Comma-separated list of roles to ignore\"\n",
    "            )\n",
    "        },\n",
    "        \n",
    "        # Define outputs\n",
    "        outputs={\n",
    "            \"markdown_output\": Output(\n",
    "                type=\"uri_file\",\n",
    "                description=\"Markdown representation of the analyzed document\"\n",
    "            ),\n",
    "            \"elements_data\": Output(\n",
    "                type=\"uri_file\",\n",
    "                description=\"CSV file containing detected elements data\"\n",
    "            ),\n",
    "            \"visualizations\": Output(\n",
    "                type=\"uri_folder\",\n",
    "                description=\"Folder containing visualization images\"\n",
    "            )\n",
    "        },\n",
    "        \n",
    "        # Define the environment\n",
    "        environment=Environment(\n",
    "            conda_file=\"enviroment/conda.yaml\",\n",
    "            image=\"mcr.microsoft.com/azureml/curated/acpt-pytorch-2.2-cuda12.1:18\"\n",
    "        ),\n",
    "        \n",
    "        # Define the command\n",
    "        command=Command(\n",
    "            program=\"python\",\n",
    "            command=\"\"\"python run.py \n",
    "                      --input_pdf ${{inputs.input_pdf}} \n",
    "                      --azure_api_key ${{inputs.azure_api_key}}\n",
    "                      --azure_endpoint ${{inputs.azure_endpoint}}\n",
    "                      --confidence_threshold ${{inputs.confidence_threshold}}\n",
    "                      --min_length ${{inputs.min_length}}\n",
    "                      --overlap_threshold ${{inputs.overlap_threshold}}\n",
    "                      --ignore_roles ${{inputs.ignore_roles}}\n",
    "                      --markdown_output ${{outputs.markdown_output}}\n",
    "                      --elements_data ${{outputs.elements_data}}\n",
    "                      --visualizations ${{outputs.visualizations}}\"\"\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return component\n",
    "\n",
    "def create_conda_env():\n",
    "    \"\"\"Create the conda environment specification.\"\"\"\n",
    "    \n",
    "    conda_env = {\n",
    "        \"name\": \"doc_analyzer_env\",\n",
    "        \"channels\": [\"conda-forge\", \"defaults\"],\n",
    "        \"dependencies\": [\n",
    "            \"python=3.9\",\n",
    "            \"pip\",\n",
    "            {\n",
    "                \"pip\": [\n",
    "                    \"azure-ai-formrecognizer>=3.2.0\",\n",
    "                    \"azure-ai-ml>=1.4.0\",\n",
    "                    \"torch>=1.12.0\",\n",
    "                    \"Pillow>=9.0.0\",\n",
    "                    \"pandas>=1.4.0\",\n",
    "                    \"numpy>=1.21.0\",\n",
    "                    \"transformers>=4.20.0\",\n",
    "                    \"nougat-ocr>=0.1.0\",\n",
    "                    \"fitz>=0.0.1\",\n",
    "                    \"PyMuPDF>=1.19.0\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save conda environment specification\n",
    "    with open(\"enviroment/conda.yaml\", \"w\") as f:\n",
    "        yaml.dump(conda_env, f)\n",
    "\n",
    "def create_run_script():\n",
    "    \"\"\"Create the run script for the component.\"\"\"\n",
    "    \n",
    "    run_script = \"\"\"\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from enhanced_document_analyzer import EnhancedDocumentAnalyzer\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Input arguments\n",
    "    parser.add_argument(\"--input_pdf\", type=str, required=True)\n",
    "    parser.add_argument(\"--azure_api_key\", type=str, required=True)\n",
    "    parser.add_argument(\"--azure_endpoint\", type=str, required=True)\n",
    "    parser.add_argument(\"--confidence_threshold\", type=float, default=0.7)\n",
    "    parser.add_argument(\"--min_length\", type=int, default=10)\n",
    "    parser.add_argument(\"--overlap_threshold\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--ignore_roles\", type=str, default=\"pageFooter,footnote\")\n",
    "    \n",
    "    # Output arguments\n",
    "    parser.add_argument(\"--markdown_output\", type=str, required=True)\n",
    "    parser.add_argument(\"--elements_data\", type=str, required=True)\n",
    "    parser.add_argument(\"--visualizations\", type=str, required=True)\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    # Parse arguments\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Create output directories\n",
    "    output_dir = Path(\"output\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    vis_dir = Path(args.visualizations)\n",
    "    vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = EnhancedDocumentAnalyzer(\n",
    "        api_key=args.azure_api_key,\n",
    "        endpoint=args.azure_endpoint,\n",
    "        output_dir=str(output_dir),\n",
    "        confidence_threshold=args.confidence_threshold,\n",
    "        min_length=args.min_length,\n",
    "        overlap_threshold=args.overlap_threshold,\n",
    "        ignor_roles=args.ignore_roles.split(\",\")\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Process document\n",
    "        markdown_text, elements_df, visualizations = analyzer.analyze_document(args.input_pdf)\n",
    "        \n",
    "        # Save markdown output\n",
    "        with open(args.markdown_output, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(markdown_text)\n",
    "        \n",
    "        # Save elements data\n",
    "        elements_df.to_csv(args.elements_data, index=False)\n",
    "        \n",
    "        # Copy visualizations to output directory\n",
    "        import shutil\n",
    "        for page_num, vis_path in visualizations.items():\n",
    "            src_path = Path(vis_path)\n",
    "            dst_path = vis_dir / src_path.name\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        print(f\"\\nProcessing complete!\")\n",
    "        print(f\"Total elements detected: {len(elements_df)}\")\n",
    "        print(f\"Visualization pages generated: {len(visualizations)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "    \n",
    "    # Save run script\n",
    "    with open(\"run.py\", \"w\") as f:\n",
    "        f.write(run_script.strip())\n",
    "\n",
    "def create_example_pipeline():\n",
    "    \"\"\"Create an example pipeline using the component.\"\"\"\n",
    "    \n",
    "    @pipeline(name=\"document_analysis_pipeline\")\n",
    "    def document_analysis_pipeline(\n",
    "        input_pdf: Input(type=\"uri_file\"),\n",
    "        azure_api_key: str,\n",
    "        azure_endpoint: str\n",
    "    ):\n",
    "        # Get the component\n",
    "        doc_analyzer = init_component()\n",
    "        \n",
    "        # Run the analysis\n",
    "        analysis_job = doc_analyzer(\n",
    "            input_pdf=input_pdf,\n",
    "            azure_api_key=azure_api_key,\n",
    "            azure_endpoint=azure_endpoint\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"markdown_output\": analysis_job.outputs.markdown_output,\n",
    "            \"elements_data\": analysis_job.outputs.elements_data,\n",
    "            \"visualizations\": analysis_job.outputs.visualizations\n",
    "        }\n",
    "    \n",
    "    return document_analysis_pipeline\n",
    "\n",
    "def main():\n",
    "    \"\"\"Set up all component files.\"\"\"\n",
    "    # Create conda environment specification\n",
    "    create_conda_env()\n",
    "    \n",
    "    # Create run script\n",
    "    create_run_script()\n",
    "    \n",
    "    # Initialize component\n",
    "    component = init_component()\n",
    "    \n",
    "    # Create example pipeline\n",
    "    pipeline = create_example_pipeline()\n",
    "    \n",
    "    print(\"Component and pipeline created successfully!\")\n",
    "    print(\"\\nTo use this component in Azure ML:\")\n",
    "    print(\"1. Package the component:\")\n",
    "    print(\"   - Ensure all files are in the same directory:\")\n",
    "    print(\"     - conda.yaml\")\n",
    "    print(\"     - run.py\")\n",
    "    print(\"     - enhanced_document_analyzer/\")\n",
    "    print(\"2. Register the component in Azure ML:\")\n",
    "    print(\"   ml_client.components.create_or_update(component)\")\n",
    "    print(\"3. Use in a pipeline as shown in the example pipeline\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
