{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81572705-2107-4393-9cd7-b9b9e54f9887",
   "metadata": {},
   "source": [
    "# Image Captioning\n",
    "\n",
    "This notebook includes the following scripts used in the image captioning logic:\n",
    "\n",
    "1) Image classification\n",
    "2) Document summarization (focus on the retrieval of key chemical concepts from a raw text)\n",
    "3) Image captions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e85410-5280-488d-b410-23ff38f49a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8ba84-2a09-4d29-b5be-7cc17d62d8af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from jinja2 import Template\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from tiktoken.core import Encoding\n",
    "from openai import AzureOpenAI\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cde1f2-bce8-489a-b8e6-8881333e1c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv(\"../my.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77966a0c-45f5-4d3f-8c42-9f057de368dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a48b6-49a4-4035-aa46-4b4c59d3f963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOCUMENT_SUMMARIZATION_SYSTEM_PROMPT = \"You are a chemistry research assistant specializing in chemical document summarization.\"\n",
    "DOCUMENT_SUMMARIZATION_USER_PROMPT = \"\"\"\n",
    "As a chemistry research assistant, summarize the document text by extracting only chemical information with accuracy and clarity.\n",
    "Focus on:\n",
    "- **Chemical Entities:** List all elements, compounds, and molecules (with IUPAC and common names if relevant).\n",
    "- **Reactions and Mechanisms:** Summarize key reactions, reactants, products, intermediates, and catalysts. Specify reaction types (e.g., oxidation, reduction) and mechanistic insights.\n",
    "- **Functional Groups and Stereochemistry:** Mention relevant functional groups, stereochemical details, and molecular structures.\n",
    "- **Experimental Conditions:** Include essential parameters like temperature, pressure, solvents, and concentrations.\n",
    "Avoid summarizing non-chemical content. Ensure professional terminology, structured clarity, and accurate representation of chemical concepts.\n",
    "The summary must be in English and well-organized for readability.\n",
    "DOCUMENT_TEXT: {{DOCUMENT_TEXT}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IMAGE_CLASSIFICATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert image classification assistant specializing in scientific and chemical images. Your task is to analyze an input image and classify it into **one of the following categories**, returning a structured JSON response.\n",
    "### **Categories:**\n",
    "1 → Logos  \n",
    "2 → Chemical molecules, reactions, formulas\n",
    "3 → Table images  \n",
    "4 → Charts (line plots, bar charts, etc., with numerical data representation)  \n",
    "5 → Process diagrams, schemas (e.g., chemical lab setup)  \n",
    "6 → Regular photos (e.g., field, lab, general photography)  \n",
    "7 → Measurements (e.g., microscopic images)  \n",
    "8 → Chemical manual writing (e.g., handwritten diagrams, chemical reactions)\n",
    "9 → Hand-written signatures\n",
    "10 → Other \n",
    "\n",
    "Always return **only a single category** that best matches the image. Prioritize **chemically and scientifically relevant** labels when applicable. Your response must be in **valid JSON format**, containing:\n",
    "- `\"image_class\"` - The assigned category number (integer from 1-9).\n",
    "- `\"probability_score\"` - Confidence level (float between 0 and 1).\n",
    "\n",
    "**Do not include any explanations, extra text, or formatting beyond the required JSON output.**\n",
    "\"\"\"\n",
    "IMAGE_CLASSIFICATION_USER_PROMPT = \"\"\"\n",
    "Classify the following image into one of the predefined categories and return a **JSON object** strictly in the following format:\n",
    "{\n",
    "  \"image_class\": <category_number>,\n",
    "  \"probability_score\": <confidence_value>\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IMAGE_CAPTIONING_SYSTEM_PROMPT = \"You are a chemistry research assistant specializing in generating precise captions for chemical images.\"\n",
    "IMAGE_CAPTIONING_USER_PROMPT = \"\"\"\n",
    "# IMPORTANT PRINCIPLES:\n",
    "## Accuracy & Completeness:\n",
    "- Use IMAGE_TITLE and DOCUMENT_CONTEXT for finding additional information to generate a presise caption.\n",
    "- Always ensure chemical names, reactions, functional groups, and molecular structures are correctly described.\n",
    "- Avoid ambiguous descriptions; explicitly state what is shown in the image.\n",
    "- Provide molecular names using both IUPAC nomenclature and common names (if applicable).\n",
    "- If oxidation states, valency, or reaction mechanisms are involved, verify correctness before captioning.\n",
    "\n",
    "## Consistency with Image Data:\n",
    "- Do not assume missing elements; caption exactly what is visible.\n",
    "- If multiple interpretations are possible, specify the conditions under which each occurs.\n",
    "- Use correct chemical terminology, including stereochemical descriptors where needed.\n",
    "\n",
    "## Response Formatting Based on Image Type:\n",
    "- Follow structured output rules for different categories of chemical images.\n",
    "- Ensure chemical equations, reaction conditions, tables, and plots are formatted precisely using Markdown where applicable.\n",
    "\n",
    "\n",
    "# IMAGE CATEGORY-SPECIFIC CAPTIONING RULES:\n",
    "## Chemical Molecules and Reactions:\n",
    "- Identify the molecule's IUPAC name and common name (if applicable).\n",
    "- Clearly state functional groups, stereochemistry, and substituents' positions.\n",
    "- Clearly state the meaning of each color if relevant, e.g. colored spheres representing atoms.\n",
    "- If the image contains a reaction, list reactants, intermediates, and products, specifying the reaction type (e.g., oxidation, reduction, condensation).\n",
    "- If the image contains a molecule, explain its structure in details, including all atoms and layers seen in an image; if multiple colors are used, explain the meaning of each one if relevant.\n",
    "- Search for additional details (names of chemical elements) in IMAGE_TITLE and DOCUMENT_CONTEXT.\n",
    "- Mention relevant catalysts, solvents, temperature, and pressure conditions.\n",
    "- Ensure electron flow and mechanistic pathways (if applicable) are correctly represented.\n",
    "\n",
    "## Microscopy & Crystallographic Images:\n",
    "- Specify the chemical composition of observed structures.\n",
    "- Indicate phase, crystal system, and lattice parameters where possible.\n",
    "- Mention any defects, grain boundaries, or other notable structural features.\n",
    "- Identify scale bars, magnification, and imaging techniques (e.g., SEM, TEM, XRD, AFM).\n",
    "\n",
    "## Experimental Laboratory Setups:\n",
    "- Provide a clear description of the setup, including essential apparatus and chemicals involved.\n",
    "- Explain experimental parameters such as temperature, pressure, pH, and reagent concentrations.\n",
    "- If the image contains a reaction, summarize its purpose and expected outcome.\n",
    "\n",
    "## Tables (Tabular Data Representation):\n",
    "- Extract all table contents exactly as shown, maintaining structure and formatting in Markdown:\n",
    "| Column 1 | Column 2 | Column 3 |\n",
    "|----------|----------|----------|\n",
    "| Data 1   | Data 2   | Data 3   |\n",
    "- Ensure all abbreviations are correctly expanded unless universally understood.\n",
    "- In case of complex table structure, ensure that markdown columns are properly shifted and completely match the table image.\n",
    "\n",
    "## Graphs, Charts, and Plots:\n",
    "- Given a line plot, bar chart, scatter plot or any other similat chart, first of all ALWAYS accurately reconstruct it in a tabular (Markdown) format (if numerical points are limited in an image, ALWAYS extrapolate them precisely to get a table), for example:\n",
    "| Time [min] (X axis) | Amount gas [ml] (Y axis) | Legend                 |\n",
    "|---------------------|--------------------------|-------------------------\n",
    "| 0                   | 0                        | Jaegers-L-00239 (Blue) |\n",
    "| 100                 | 200                      | Jaegers-L-00239 (Blue) |\n",
    "- Don't discribe visual aspects of graphs, charts, and plots. Focus on quantitative data.\n",
    "- Summarize (numerically) notable trends, peak values, inflection points, and outliers.\n",
    "- Include equation-based descriptions for any regression models, best-fit lines, or calculated values.\n",
    "\n",
    "## Handwritten Notes (Formulas, Reactions, Calculations):\n",
    "- Transcribe chemical equations, formulas, and reaction mechanisms with precision.\n",
    "- Ensure correct subscripts, superscripts, charges, and reaction arrows.\n",
    "- If handwritten content is ambiguous, provide a clarification note while maintaining the original meaning.\n",
    "\n",
    "\n",
    "# COMMON ERRORS TO AVOID:\n",
    "## Missing Key Observations:\n",
    "- Ensure all significant features (e.g., acetate presence in crystal images) are described.\n",
    "\n",
    "## Ambiguous Abbreviations:\n",
    "- Expand uncommon abbreviations unless contextually evident.\n",
    "\n",
    "## Incorrect Functional Group Assignments:\n",
    "- Validate oxidation states, functional group transformations, and reaction mechanisms.\n",
    "- Avoid confusion between aldehydes, ketones, alcohols, and carboxylic acids.\n",
    "\n",
    "## Incomplete Molecular Descriptions:\n",
    "- Always specify where substituents are attached (e.g., \"X is on the 3-position of the phenyl ring\").\n",
    "\n",
    "\n",
    "# FINAL OUTPUT FORMAT REQUIREMENTS\n",
    "- Responses must be structured in Markdown where applicable.\n",
    "- Chemical equations and formulas should be formatted correctly, using LaTeX notation where necessary.\n",
    "- Tables and numerical data must be accurately transcribed in Markdown table format.\n",
    "- Captions must be precise, detailed, and contextually appropriate for a professional audience.\n",
    "- Avoid assumptions and describe only the observable features in the image.\n",
    "\n",
    "IMAGE_TITLE: {{IMAGE_TITLE}}\n",
    "DOCUMENT_CONTEXT: {{DOCUMENT_CONTEXT}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb1977-cab1-4ac1-93dc-93fa9686e5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_image(image_path: str, max_image_size=20971520) -> bool:\n",
    "    \"\"\"Validate if the image is suitable for processing.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image file does not exist: {image_path}\")\n",
    "            return False\n",
    "\n",
    "        # Check file size\n",
    "        file_size = os.path.getsize(image_path)\n",
    "        if file_size > max_image_size:\n",
    "            print(f\"Image too large ({file_size} bytes): {image_path}\")\n",
    "            return False\n",
    "\n",
    "        # Verify image can be opened and is valid\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()\n",
    "        # Check if image has valid dimensions\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            if width == 0 or height == 0:\n",
    "                print(f\"Invalid image dimensions: {image_path}\")\n",
    "                return False\n",
    "\n",
    "            if width > 32768 or height > 32768:\n",
    "                print(f\"Image dimensions too large: {width}x{height}\")\n",
    "                return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Image validation failed for {image_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    \n",
    "def preprocess_image(image_path: str) -> Optional[Image.Image]:\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            if img.mode not in ('RGB', 'L'):\n",
    "                img = img.convert('RGB')\n",
    "\n",
    "            max_dimension = 2048\n",
    "            if img.width > max_dimension or img.height > max_dimension:\n",
    "                ratio = min(max_dimension / img.width, max_dimension / img.height)\n",
    "                new_size = (int(img.width * ratio), int(img.height * ratio))\n",
    "                img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            img.save(img_byte_arr, format='JPEG', quality=85)\n",
    "            img_byte_arr.seek(0)\n",
    "\n",
    "            return Image.open(img_byte_arr)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image preprocessing failed for {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "def encode_image(image_path: str) -> Optional[str]:\n",
    "    \"\"\"Encode image as base64 with proper validation and preprocessing.\"\"\"\n",
    "    try:\n",
    "        if not validate_image(image_path):\n",
    "            return None\n",
    "\n",
    "        processed_img = preprocess_image(image_path)\n",
    "        if processed_img is None:\n",
    "            return None\n",
    "\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        processed_img.save(img_byte_arr, format='JPEG', quality=85)\n",
    "        img_byte_arr.seek(0)\n",
    "        base64_encoded = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "\n",
    "        try:\n",
    "            base64.b64decode(base64_encoded)\n",
    "            return base64_encoded\n",
    "        except Exception as e:\n",
    "            print(f\"Base64 validation failed for {image_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image encoding failed for {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_image_classification(image_path, client, deployment_name):\n",
    "    try:\n",
    "        base64_image = encode_image(image_path)\n",
    "        if not base64_image:\n",
    "            print(f\"Skipping caption generation for invalid image: {image_path}\")\n",
    "            return \"\"\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model = deployment_name,\n",
    "                    response_format={ \"type\": \"json_object\" },\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": IMAGE_CLASSIFICATION_SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \n",
    "                                 \"text\": IMAGE_CLASSIFICATION_USER_PROMPT\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"image_url\",\n",
    "                                    \"image_url\": {\n",
    "                                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=100\n",
    "                )\n",
    "                return json.loads(response.choices[0].message.content)\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Image classification attempt {attempt + 1} failed: {str(e)}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"All image classification attempts failed for {image_path}\")\n",
    "                    return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Image classification failed: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_summary(raw_text, client, deployment_name):\n",
    "    try:\n",
    "        template = Template(DOCUMENT_SUMMARIZATION_USER_PROMPT)\n",
    "        user_prompt = template.render(DOCUMENT_TEXT=raw_text)\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    model = deployment_name,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": DOCUMENT_SUMMARIZATION_SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \n",
    "                                 \"text\": user_prompt\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=4000\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Summary generation attempt {attempt + 1} failed: {str(e)}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"All summary generation attempts failed for {image_path}\")\n",
    "                    return \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Summary generation failed: {str(e)}\")\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "def generate_caption(image_path, figure_title, document_summary, vision_client, vision_deployment_name) -> str:\n",
    "    \"\"\"Generate image caption using GPT-4 Vision.\"\"\"\n",
    "    try:\n",
    "        base64_image = encode_image(image_path)\n",
    "        if not base64_image:\n",
    "            print(f\"Skipping caption generation for invalid image: {image_path}\")\n",
    "            return \"\"\n",
    "        \n",
    "        template = Template(IMAGE_CAPTIONING_USER_PROMPT)\n",
    "        user_prompt = template.render(IMAGE_TITLE=figure_title, DOCUMENT_CONTEXT=document_summary)\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = vision_client.chat.completions.create(\n",
    "                    model = vision_deployment_name,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": IMAGE_CAPTIONING_SYSTEM_PROMPT\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \n",
    "                                 \"text\": user_prompt\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"image_url\",\n",
    "                                    \"image_url\": {\n",
    "                                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=2000\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Caption generation attempt {attempt + 1} failed: {str(e)}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"All caption generation attempts failed for {image_path}\")\n",
    "                    return \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Caption generation failed for {image_path}: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43815248-97e0-43d9-b398-df01b9db4801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoai_vision_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc9460-5f84-4005-ae03-f582ab815aee",
   "metadata": {},
   "source": [
    "### Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d01f31-a6e9-4053-8941-24e235d757d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = \"<IMAGE PATH>\"\n",
    "result = get_image_classification(image_path, aoai_vision_client, AZURE_OPENAI_DEPLOYMENT_NAME)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71707333-f8ef-4c89-9c02-424c2a7c1b88",
   "metadata": {},
   "source": [
    "### Document summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7f9a1-7845-47fc-ad15-e4a84f0b3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_raw_text = \"<DOCUMENT RAW TEXT>\"\n",
    "document_summary = get_summary(document_raw_text, aoai_vision_client, AZURE_OPENAI_DEPLOYMENT_NAME)\n",
    "document_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e16173-fcc7-4ced-a2f7-48f08e770038",
   "metadata": {},
   "source": [
    "### Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b087d9c-871a-483e-83ca-57f548ae5de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = \"<IMAGE PATH>\"\n",
    "document_summary = \"<DOCUMENT SUMMARY>\"\n",
    "figure_title = \"<FIGURE TITLE>\" # can be empty\n",
    "\n",
    "image_caption = generate_caption(image_path, figure_title, document_summary, aoai_vision_client, AZURE_OPENAI_DEPLOYMENT_NAME)\n",
    "image_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192a226-7943-471b-9fe3-fa6a334c7840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
